# Pre-Ingestion Layer Integration Guide

## ğŸ“‹ Overview

This guide describes the integration of the **Pre-Ingestion Layer** (PySpark batch processing with MLlib) into the **Multimodal Lambda Architecture** (Kafka + Spark Streaming + Cassandra + Flask API).

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 PRE-INGESTION LAYER (BATCH)                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚ CSV Files   â”‚  â”‚ JPG Images   â”‚  â”‚ Spark Local   â”‚          â”‚
â”‚  â”‚ (3 files)   â”‚  â”‚ (HDFS)       â”‚  â”‚ Processing    â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                           â†“                                       â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚         â”‚  pre_ingestion_layer.py         â”‚                     â”‚
â”‚         â”‚  + compute_texture_features.py  â”‚                     â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                       â†“                                           â”‚
â”‚    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—            â”‚
â”‚    â•‘  HDFS (localhost:8020)                        â•‘            â”‚
â”‚    â•‘  â€¢ processed_images.parquet (21 cols, 27K)   â•‘            â”‚
â”‚    â•‘  â€¢ texture_features.parquet (15 cols, 27K)   â•‘            â”‚
â”‚    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             SPEED LAYER (REAL-TIME STREAMING)                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚  Simplified Producer                                   â”‚      â”‚
â”‚  â”‚  â€¢ Reads from HDFS Parquet (pre-computed)             â”‚      â”‚
â”‚  â”‚  â€¢ No CSV loading, no feature extraction              â”‚      â”‚
â”‚  â”‚  â€¢ Streams 35+ features per event                     â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                           â†“                                       â”‚
â”‚            â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—                       â”‚
â”‚            â•‘  KAFKA (localhost:29092)    â•‘                       â”‚
â”‚            â•‘  Topic: enhanced-multimodal â•‘                       â”‚
â”‚            â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â”¬â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                       â”‚
â”‚                          â†“                                        â”‚
â”‚            â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“                       â”‚
â”‚            â”ƒ  SPARK STREAMING            â”ƒ                       â”‚
â”‚            â”ƒ  â€¢ Parse enriched events    â”ƒ                       â”‚
â”‚            â”ƒ  â€¢ Aggregate by class       â”ƒ                       â”‚
â”‚            â”ƒ  â€¢ Detect anomalies         â”ƒ                       â”‚
â”‚            â”—â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›                       â”‚
â”‚                        â†“                                          â”‚
â”‚        â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—                         â”‚
â”‚        â•‘  CASSANDRA (localhost:9042)   â•‘                         â”‚
â”‚        â•‘  â€¢ multimodal_tabular_stats   â•‘                         â”‚
â”‚        â•‘  â€¢ multimodal_image_stats     â•‘                         â”‚
â”‚        â•‘  â€¢ multimodal_ml_features  âœ¨ â•‘                         â”‚
â”‚        â•‘  â€¢ multimodal_texture_statsâœ¨ â•‘                         â”‚
â”‚        â•‘  â€¢ multimodal_anomalies       â•‘                         â”‚
â”‚        â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â”¬â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                SERVING LAYER (API + DASHBOARD)                   â”‚
â”‚  â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“                                      â”‚
â”‚  â”ƒ  Flask API (Port 5000) â”ƒ                                      â”‚
â”‚  â”ƒ  â€¢ Legacy endpoints    â”ƒ                                      â”‚
â”‚  â”ƒ  â€¢ Enhanced endpointsâœ¨â”ƒ                                      â”‚
â”‚  â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ¯ Key Features

### Pre-Computed Features (from Pre-Ingestion)
- **CSV Features**: NDVI stats, spectral bands (9 features)
- **ML Vectors**: raw_features (10D), final_features (10D normalized)
- **Encoded Features**: vegetation_index_encoded (one-hot)
- **Texture Features**: GLCM (6), LBP histogram (8)
- **Total**: 35+ features per image

### New Capabilities
âœ… **10x faster producer** (no on-the-fly feature extraction)
âœ… **ML-ready vectors** (pre-normalized with StandardScaler)
âœ… **Texture intelligence** (GLCM + LBP for advanced analysis)
âœ… **Three-way fusion** (CSV + RGB + Texture)
âœ… **Production-ready pipeline** (reproducible with saved model)

## ğŸ“¦ Installation & Setup

### 1. Prerequisites

```bash
# Python packages
pip install pyspark==3.5.1
pip install kafka-python
pip install cassandra-driver
pip install flask flask-cors

# Docker (already installed)
docker --version
docker-compose --version
```

### 2. Start Infrastructure

```bash
# Start all services (HDFS, Kafka, Cassandra, Spark)
docker-compose up -d

# Wait for services to be ready (30-60 seconds)
docker-compose ps

# Verify HDFS
hdfs dfs -ls hdfs://localhost:8020/data/processed/

# Expected output:
# - hdfs://localhost:8020/data/processed/processed_images.parquet
# - hdfs://localhost:8020/data/processed/texture/texture_features.parquet
```

### 3. Initialize Cassandra Schema

```bash
# Apply enhanced schema
docker exec -i cassandra cqlsh < infrastructure/cassandra_enhanced.cql

# Verify tables created
docker exec -i cassandra cqlsh -e "DESCRIBE KEYSPACE landcover;"
```

### 4. Run the Pipeline

#### Step 1: Start Kafka Producer

```bash
# Terminal 1: Producer (reads from Parquet, streams to Kafka)
cd src/producer
python kafka_producer_from_parquet.py

# Expected output:
# âœ“ Loaded 27000 processed images
# âœ“ Loaded 27000 texture feature records
# âœ“ Joined DataFrame contains 27000 records
# âœ“ Streaming events to Kafka...
# Progress: 100/27000 events sent (0.4%)
# ...
# Successfully sent: 27000
```

#### Step 2: Start Spark Streaming

```bash
# Terminal 2: Spark Streaming (processes Kafka â†’ Cassandra)
cd src/speed_layer
spark-submit \
  --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1,com.datastax.spark:spark-cassandra-connector_2.12:3.4.1 \
  spark_streaming_enhanced.py

# Expected output:
# âœ“ Enhanced streaming job started
# Processing Enhanced Batch 0
# âœ“ Tabular features aggregated (10 classes)
# âœ“ ML features aggregated (10 classes, dim=10)
# âœ“ Texture features aggregated (10 classes)
# âœ“ Image stats updated (10 classes)
# âœ“ Enhanced anomalies detected: X
```

#### Step 3: Start Flask API

```bash
# Terminal 3: API Server
cd src/serving
python app_enhanced.py

# Expected output:
# ENHANCED MULTIMODAL API SERVER
# Integration: Pre-Ingestion Layer + Lambda Architecture
# Port: 5000
# Documentation: http://localhost:5000/
```

### 5. Test the API

```bash
# Health check
curl http://localhost:5000/api/health

# Enhanced summary
curl http://localhost:5000/api/enhanced/summary

# ML features
curl http://localhost:5000/api/enhanced/ml-features

# Texture statistics
curl http://localhost:5000/api/enhanced/texture-stats

# Feature importance
curl http://localhost:5000/api/enhanced/feature-importance

# Class comparison (all features)
curl http://localhost:5000/api/enhanced/class-comparison
```

## ğŸ“Š API Endpoints

### Legacy Endpoints (Backward Compatible)
- `GET /api/realtime/ndvi` - Real-time NDVI statistics
- `GET /api/anomalies` - Anomaly alerts
- `GET /api/multimodal/tabular-stats` - Tabular features
- `GET /api/multimodal/image-stats` - Image features
- `GET /api/multimodal/anomalies` - Multimodal anomalies
- `GET /api/multimodal/cumulative-totals` - Event totals

### Enhanced Endpoints (NEW)
- `GET /api/enhanced/ml-features` - ML-ready feature vectors
- `GET /api/enhanced/ml-features/<class>` - ML features by class
- `GET /api/enhanced/texture-stats` - Texture statistics (GLCM + LBP)
- `GET /api/enhanced/texture-stats/<class>` - Texture stats by class
- `GET /api/enhanced/feature-importance` - Feature importance ranking
- `GET /api/enhanced/summary` - Comprehensive system summary
- `GET /api/enhanced/class-comparison` - Cross-modal class comparison

## ğŸ—„ï¸ Database Schema

### New Tables

#### multimodal_ml_features
Stores pre-computed, normalized feature vectors for ML applications.

```sql
class_name TEXT PRIMARY KEY
avg_final_features TEXT  -- JSON array of normalized features
feature_dimension INT    -- Dimension (e.g., 10)
sample_count BIGINT
last_updated TIMESTAMP
```

#### multimodal_texture_stats
Stores aggregated texture features (GLCM + LBP).

```sql
class_name TEXT PRIMARY KEY
glcm_contrast_avg DOUBLE
glcm_homogeneity_avg DOUBLE
glcm_energy_avg DOUBLE
glcm_correlation_avg DOUBLE
glcm_dissimilarity_avg DOUBLE
glcm_asm_avg DOUBLE
lbp_entropy_avg DOUBLE
texture_sample_count BIGINT
last_updated TIMESTAMP
```

## ğŸ”§ Troubleshooting

### Issue: Producer can't read Parquet files

```bash
# Check if files exist in HDFS
hdfs dfs -ls hdfs://localhost:8020/data/processed/

# If missing, run pre-ingestion layer
python pre_ingestion_layer.py
python compute_texture_features.py
```

### Issue: Cassandra connection refused

```bash
# Check if Cassandra is running
docker ps | grep cassandra

# Check Cassandra logs
docker logs cassandra

# Wait for Cassandra to be fully ready
docker exec cassandra cqlsh -e "SELECT now() FROM system.local;"
```

### Issue: Kafka topic not found

```bash
# List Kafka topics
docker exec kafka kafka-topics --list --bootstrap-server localhost:9092

# Create topic manually if needed
docker exec kafka kafka-topics --create \
  --topic enhanced-multimodal-events \
  --bootstrap-server localhost:9092 \
  --partitions 1 \
  --replication-factor 1
```
Common Issues & Solutions
Issue	Symptoms	Solution
Kafka not available	TimeoutException: Timed out waiting for node	sudo docker compose restart zookeeper kafka
Cassandra connection refused	NoHostAvailable	sudo docker compose restart cassandra
HDFS permission denied	AccessControlException	sudo docker compose exec namenode hdfs dfs -chmod -R 777 /user/hive
Spark Streaming stops	Process exits after 30s	Check logs: tail -f logs/spark_streaming.log
Flask API 500 errors	API returns errors	Check Cassandra connection: curl http://localhost:5000/api/health
Dashboard not loading	Blank page	Check Flask logs: tail -f logs/flask_api.log
JARs not found	ClassNotFoundException	Re-run startup script to download JARs
Port already in use	Address already in use	Kill existing processes: pkill -f spark_streaming_enhanced

## ğŸ“ˆ Performance Metrics

| Metric | Before Integration | After Integration | Improvement |
|--------|-------------------|-------------------|-------------|
| **Producer Speed** | 100-200 events/s | 1000-2000 events/s | **10x faster** |
| **Feature Count** | 15 features | 35+ features | **133% more** |
| **Processing Time** | 5ms/image (extraction) | 0ms (pre-computed) | **Instant** |
| **ML Readiness** | Manual scaling | Pre-normalized | **Production ready** |
| **Texture Analysis** | None | GLCM + LBP (14 features) | **NEW capability** |

## ğŸ“š File Structure

```
remote-satellite-lambda-pipeline/
â”‚
â”œâ”€â”€ docker-compose.yml                      # Unified infrastructure
â”œâ”€â”€ INTEGRATION_GUIDE.md                    # This file
â”‚
â”œâ”€â”€ pre_ingestion_layer.py                  # Batch processing (keep)
â”œâ”€â”€ compute_texture_features.py             # Texture extraction (keep)
â”œâ”€â”€ PRE_INGESTION_LAYER.md                  # Pre-ingestion docs
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ producer/
â”‚   â”‚   â””â”€â”€ kafka_producer_from_parquet.py  # NEW - simplified producer
â”‚   â”‚
â”‚   â”œâ”€â”€ speed_layer/
â”‚   â”‚   â””â”€â”€ spark_streaming_enhanced.py     # NEW - enhanced streaming
â”‚   â”‚
â”‚   â””â”€â”€ serving/
â”‚   |    â””â”€â”€ app_enhanced.py                # NEW - enhanced API
|   |
â”‚   â””â”€â”€ pre_ingestion_layer/    
|       |
|       â”œâ”€â”€ compute_texture_features.py
|       â”œâ”€â”€ load_texture_data.py
|       â”œâ”€â”€ pre_ingestion_layer.py
|       â”œâ”€â”€ verify_hdfs_output.py
|       â””â”€â”€ verify_texture_features.py
|
â”œâ”€â”€ infrastructure/
â”‚   â””â”€â”€ cassandra_enhanced.cql              # NEW - extended schema
â”‚
â””â”€â”€ hdfs/                                   # Your pre-computed data
    â”œâ”€â”€ namenode/
    â””â”€â”€ datanode/
```

## ğŸš€ Next Steps

1. **Run end-to-end test** with all 27K images
2. **Monitor performance** (throughput, latency)
3. **Add dashboard visualizations** for texture features
4. **Implement batch queries** for historical analysis
5. **Scale up** (add more Kafka partitions, Spark workers)

## ğŸ“ Notes

- **Data persistence**: HDFS data persists in `./hdfs/` directory
- **Checkpoints**: Spark checkpoints in `/tmp/spark_enhanced_ckpt`
- **Kafka retention**: Default 7 days (configurable)
- **Cassandra**: Data persists in Docker volume `cassandra_data`

## ğŸ“ Key Learnings

1. **Pre-computation wins**: Feature extraction is expensive - do it once!
2. **Parquet is efficient**: 27K rows load in <2 seconds
3. **MLlib pipelines**: Reproducible, serializable, production-ready
4. **Texture adds value**: GLCM/LBP reveal patterns invisible to raw pixels
5. **Integration simplifies**: Unified architecture beats scattered scripts

---

**Questions?** Check the API documentation at `http://localhost:5000/`
